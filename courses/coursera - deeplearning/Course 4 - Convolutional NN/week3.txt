--- Detection Algorithms --- 

    -- Object Localization --
        . identifying the position/bounding box of an object in a image
        . just 1 object per image instead of multiple objects to detect (object detection problem)

        - Classification with Localizaton -
            . output of model is the tradition classification softmax + the bounding box coordinates (4 values)
            -> Bounding box is defined by the center point (bx, by) and dimentions (bw, bh)
                . coordinate values are relative (0-1), where (0,0) is top left corner.

            Y - [Pc, bx, by, bh, bw, C1, C2, ..., CC]     
                . Pc -> "is having an object?" (1 or 0)
                    . only if there is an object, Pc = 1, the rest of the values are valid, and the model "cares about it!" (dont do backprop on them)
                . bx, by, bh, bw -> BB values
                . C1, C2, ... -> the classes (regular softmax output)

             ->> Loss Function
                . L (y_pred, y) = (y0_pred - y0)^2 + (...)^2 + (yl_pred - yl)^2   <-- if y0 == 1 (Pc = 1)
                                = (y0_pred - y0)^2 <-- if y0 == 0


    -- Landmark Dectection --
            . output x,y coordinates of important "landmarks" on a picture (e.g: corner of an eye of a person)
                . used for identifying important landmarks in a face/body, for emotion recognition, pose detection, snapchat AR filters, etc..

-- Object Detection --
    --Sliding Windows--
        . Using convolution/ConvNet to achieve the sliding windows

            -Car Detection Example:
                i. Have training data of cropped cars (car filling almost all the picture) and images without cars
                ii. Train a ConvNet so it is able to classify this images (cropped ones)
                iii. Do a sliding window in a similar way as you do the convolution operation through an image (pick an filter size (hxw) and a stride, and feed this window into the initial ConvNet
                iv. Repeat using different window sizes

                -> This is very expensive, as you have to classify every window with ConvNet (which is expensive!)...not duable...
                ->> Solution is to use a convolutional implementation!!

    -- Convolutional Implementation of Sliding Windows --
        . Reuse the calculations that are shared between overlapping windows, so you have to make less calculations
        -> Turn FC layer into CONV layer
            use 1x1xn_C dimention volume
        -> Input a slightly bigger window then your windows size to the ConvNet (2 more pixels in each direction), and the FC layer will be instead 2x2xn_C (if you input just a slightly bigger window what is the size total area of 4 overlapping sliding windows), and you are now calculating 4 windows in one pass, with a much smaller computational overhead as a lot of the convolutional calculations are shared and reused ( on the part of image that is commun)
            -> 8 pixels bigger -> 8x8 sliding windows
            ->> DO THE ENTIRE IMAGE <<-
        
        ISSUE: it does not output the most accurate bounding box for the object (just the window where it is)

    -- Bounding Box Prediction - YOLO Algorithm --
        . YOLO - You Only Look Once : https://arxiv.org/abs/1506.02640

        . Divide the image in a grid (10x10, 19x19) and apply the Localization algorithm to each cell
            . the output is the same Y = [ Pc, bx, by, bh, bw, C1, ..., CC]
            . even if an object spans accross multiple cells, only the cell which contains the center of its bounding box has Pc=1 (has a valid object!)
            . The target output "volume" of the ConvNet is all the cells Y combined, so for example for 3x3grid with C=3 (Yi = 8x1) is: 3x3x8
                -> This is a convolutional implementation (lots of shared computation, very effecient, used for realtime detection)!!!!
            -> This model output precise bounding boxes for the objects!

            . Finer grid helps to solve the issue of having multiple objects per cell

        - Bounding Boxes Encoding -
            . Relative to the position and size of the Cell
                . bx, by is a relative value (0-1) for the relative position on the cell
                . bh, bw is relative to the size of the cell (can be larger than the cell, thus could be > 1)

        - Intersection Over Union - IoU -
            . metric to evaluate how good is the object localization (if the bounding boxes are perfect, or not the correct size / offsetted)
            . measure of the overlap between two bounding boxes

            -> IoU = intersection area of predicted bb VS actual bb / union area of predicted bb vs actual bb
                . "Correct" if IoU > 0.5  (normal convection for this value)

        - Non-max Suppression - 
            . method to make sure the algorithm only detects the same object ONCE (bc it can span over multiple cells, and multiple cells can predict the detection of the same object -> by predicting that the center of the BB lies on its cell)

            -> Clean up the multiple detections that are not the maximum probability
                
                -> Algorithm
                . on a 19x19 grid, you get an output of 19x19x5 (5, bc of Pc, bx, by, bh, bw...only one category)
                i. discard all boxes with Pc<0.6
                ii. Use the detection with the highest 'Pc' (probablity of having the object), from all detections
                iii. Supress the other object detection BBs that have a high IoU (IoU > 0.5) with the initial detection (with highest Pc, found on ii.)
                iiii. Repeat ii., for the next highest (that was not surpressed)

                NOTE: for multiple objects, do this algorithm for each object individually.

        - Anchor Boxes -
            . Detection of multiple objects per cell (previously only 1 object per Y, as you only detect one bounding box!)
            . Use predefined bounding boxes -> Anchor Boxes, for "categorizing" different object detection in the same cell

            . Output will be Y multiplied by the number of different anchor boxes Y = [Ya_b_0, Ya_b_1, ...]
            . Assign the detected bounding box output to the component of the output Y (Ya_b_i) with the highest IoU between detection and anchor box centered in the same detected center

            . If no dectection for a specific Anchor box, just assing Ya_b_i Pc to 0
            
            . Issue: algorithm does not handle well if there are more objects detected in the cell than the number of anchor boxes, or 2 obejcts detected for the same anchor box
                . Use some kind of tie braker, like highest Pc...

            -> Anchor Boxes allow the algorithm to speciallize in the detection of shapes that have a characteristic shape (like pedestrians vs cars)

            -> Anchor Boxes Shape Selection:
                Manual (5 to 10)
                Automatic: use a K-means algorithm to group together the types of object shapes you tend to get and select a set of anchor boxes from that group

    -- YOLO Algorithm Implementation --

        . Example:
            3x3 grid
            3 classes: 1-pedestrian, 2-car, 3-motocycle
            2 anchor boxes

        y = 3x3x2x8 (2 is for the #anchor boxes, 8 -> 5 + #classes)

        input (100x100x3) -> ConvNet -> output (3x3x2x8)

        do non-max supression on the outputs

    -- Region Proposals - R-CNN --
        . Not very used -> optional literature... YOLO is better
        -> Some areas of the image is pointeless to run the sliding windows (top of image for example)
            . Just run the sliding windows on certain "regions" of the image

        - How to find these regions? -
            . Run an image segmentation algorithm (like segument areas where the color change,,,probably a new object is there), and just try to detect on those regions
                -> this segmentation algorithm detectes "blobs" in the image (like 1000)...run ConvNet classifier algorithm on those blobs

        Problem: slow, lots of blobs to compute, and only of these proposed regions is classified at a time 
           
            -> Fast R-CNN: use a convolutional implementation of sliding windows to classify all the proposed regions in one go! 
                . Getting the proposed regions with the traditional segmentation algorithm is still slow..

            -> Faster R-CNN: use a convolutional network to propose the regions!!!
                . Better but still slower than YOLO!

        



        







            

            












        
 




    

